{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:21:53.368715Z",
     "start_time": "2024-03-26T23:21:45.937914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16979\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取JSON文件\n",
    "df_original = pd.read_json('data/AMAZON_FASHION.json', lines=True)\n",
    "df = df_original[['overall', 'reviewText']]\n",
    "\n",
    "# 去除缺失值\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630e46fc99b051cb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T23:31:21.392404Z",
     "start_time": "2024-03-26T23:26:24.699049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/882403 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9940ebc4b8014bca8af23e784b3111b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16979\\AppData\\Local\\Temp\\ipykernel_71016\\1556853919.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['processed_review'] = df['reviewText'].progress_apply(preprocess_text)\n",
      "C:\\Users\\16979\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": "   overall                                   processed_review\n0        5                                       exactli need\n1        2  agre review open small almost bent hook expens...\n2        4  love go order anoth pack keep work someon incl...\n3        2                                          tini open\n4        3                                               okay",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>processed_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>exactli need</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>agre review open small almost bent hook expens...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>love go order anoth pack keep work someon incl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>tini open</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>okay</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 为pandas的apply方法添加tqdm进度条功能\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# 文本清洗\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 分词\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# 去除停用词\n",
    "def remove_stopwords(words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "# 词干提取\n",
    "def stem_words(words):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "# 预处理流程\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    words = tokenize_text(text)\n",
    "    words = remove_stopwords(words)\n",
    "    words = stem_words(words)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# 应用预处理，并添加进度条\n",
    "df['processed_review'] = df['reviewText'].progress_apply(preprocess_text)\n",
    "df.drop(['reviewText'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.to_csv('data/AMAZON_FASHION.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T23:49:47.304270Z",
     "start_time": "2024-03-26T23:49:45.622784Z"
    }
   },
   "id": "8f10dc808a546d95",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5bd584374a4547",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 划分数据集：首先划分出训练集和剩余部分（后续分为验证集和测试集）\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df['reviewText'], df['overall'], test_size=0.3, random_state=42)\n",
    "\n",
    "# 再将剩余部分划分为验证集和测试集\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d390f674e48a5e35",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-25T04:08:33.600993Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438f5b3e43bf47ca862026f741e7b0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16979\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\16979\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83f3534ccdf4493abb9b3fb6ee9a842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c405f16a1c1c49ea9e5aa91c8adc2b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a796b100aa97425ba7c6a7d3c3ff153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b56aa752fc14287b1d3983247224814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\16979\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c0ca5fb5d645cf8001c8e548a55f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/77211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 48\u001B[0m\n\u001B[0;32m     46\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m     47\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 48\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     51\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining_loss\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{:.3f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(loss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(batch))})\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:259\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    250\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    251\u001B[0m     (inputs,)\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, (torch\u001B[38;5;241m.\u001B[39mTensor, graph\u001B[38;5;241m.\u001B[39mGradientEdge))\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m()\n\u001B[0;32m    256\u001B[0m )\n\u001B[0;32m    258\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[1;32m--> 259\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:142\u001B[0m, in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[0;32m    136\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    137\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad can be implicitly created only for real scalar outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    138\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mout\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    139\u001B[0m         )\n\u001B[0;32m    140\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[0;32m    141\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 142\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     )\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    145\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载预训练的BERT模型和分词器\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(df['overall'].unique())).to(device)\n",
    "\n",
    "# 准备数据集\n",
    "def encode_reviews(reviews):\n",
    "    return tokenizer.batch_encode_plus(reviews, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# 对数据集进行编码\n",
    "encoded_data_train = encode_reviews(X_train.tolist())\n",
    "encoded_data_val = encode_reviews(X_val.tolist())\n",
    "\n",
    "# 创建Tensor数据集\n",
    "dataset_train = TensorDataset(encoded_data_train['input_ids'], encoded_data_train['attention_mask'], torch.tensor(y_train.tolist()))\n",
    "dataset_val = TensorDataset(encoded_data_val['input_ids'], encoded_data_val['attention_mask'], torch.tensor(y_val.tolist()))\n",
    "\n",
    "# 数据加载器\n",
    "batch_size = 8\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size)\n",
    "\n",
    "# 优化器\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "        model.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_f1 = 0\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        logits = outputs[1]\n",
    "        loss = outputs[0]\n",
    "        val_loss += loss.item()\n",
    "        predictions = torch.argmax(logits, dim=1).flatten()\n",
    "        labels = inputs['labels']\n",
    "        val_f1 += f1_score(labels.cpu(), predictions.cpu(), average='weighted')\n",
    "    \n",
    "    val_loss /= len(dataloader_val)\n",
    "    val_f1 /= len(dataloader_val)\n",
    "    tqdm.write(f'\\nEpoch {epoch} | Val Loss: {val_loss:.3f} | Val F1: {val_f1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3994c0c553d5eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T04:07:03.249033Z",
     "start_time": "2024-03-25T04:06:21.074461Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
